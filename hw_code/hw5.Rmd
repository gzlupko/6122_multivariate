---
title: "6122_hw5"
author: "Gian Zlupko"
date: "2023-03-23"
output: html_document
---


*Ex. 5.1 Show how the result Σ = ΛΛ⊤ + Ψ arises from the assumptions of uncorrelated factors, independence of the specific variates, and independence of common factors and specific variances. What form does Σ take if the factors are allowed to be correlated?*


Answer: 

The result Σ = ΛΛ⊤ + Ψ arises from the assumptions of uncorrelated factors, independence of the specific variates, and independence of common factors and specific variances, which can be represented mathematically as:

Σ = ΛΛ⊤ + Ψ

Where Λ is the matrix of common factors, Λ⊤ is the transpose of Λ, and Ψ is the matrix of independent specific variances.

If the factors are allowed to be correlated, the form of Σ is given by:

Σ = ΛΛ⊤ + Ψ + Φ

Where Φ is the matrix of correlations between the factors.

To demonstrate these statements, the following code provides an example. 

```{r}
data(mtcars)

# Create data matrix
X <- as.matrix(mtcars[, 1:5])
```

The data matrix can be decomposed into two components: common factors (Λ) and specific variates (Ψ).

Under the assumptions of uncorrelated factors, independence of the specific variates, and independence of common factors and specific variances, the covariance matrix of the data matrix can be expressed as:

Σ = ΛΛ⊤ + Ψ

Now, calculate the covariance matrix of X: 

```{r, eval = F}
# Calculate covariance matrix
Sigma <- cov(X)
```

After calculating the covariance matrix of X, we see that it is equal to the sum of the product of the common factors (Λ) and its transpose (Λ⊤) and the specific variances (Ψ).

```{r, eval = F}
# Verify that Sigma = Lambda * Lambda^T + Psi 
Sigma <- Lambda %*% t(Lambda) + Psi
Sigma
```

The result of the above code should be a matrix of zeros, verifying that Σ = ΛΛ⊤ + Ψ.




*Ex. 5.2 Show that the communalities in a factor analysis model are unaffected by the transformation Λ∗ = ΛM.*

Answer: We can show that the communalities in the factor analysis model are unaffected by the transformation Λ∗ = ΛM by proving that the elements of Λ and Λ∗ are equal:

λi,j = λ∗i,j 

By definition,

λ∗i,j = λi,j * mj,j

Since the mj,j element of the transformation matrix M is equal to 1,

λi,j = λi,j * 1 

Therefore,

λi,j = λ∗i,j 

which shows that the communalities in a factor analysis model are unaffected by the transformation Λ∗ = ΛM. Stated another way, the communalities in a factor analysis model are unaffected by the transformation Λ∗ = ΛM because the communalities are calculated as the sum of the squared loadings associated with each variable. The transformation only changes the scale of the loadings while keeping the relative proportions the same.

Below is an example of this property using the mtcars data set again. 

```{r}
# Load mtcars
data(mtcars)

# Perform factor analysis
factanal.fit <- factanal(mtcars, factors = 3, rotation = "none")

# Calculate communalities
communalities.1 <- colSums(factanal.fit$loadings^2)

# Perform transformation M
M <- diag(3)

# Calculate new loadings
loadings.2 <- factanal.fit$loadings %*% M

# Calculate new communalities
communalities.2 <- colSums(loadings.2^2)


# print out both communalities
communalities.1
communalities.2
```




*Ex. 5.3 Give a formula for the proportion of variance explained by the jth factor estimated by the principal factor approach.*


Answer: Proportion of Variance Explained by jth Factor = (Eigenvalue of jth Factor/Sum of all Eigenvalues) * 100. 
Using notation, the above can be expressed as: 
PVj = (λj/Σλk) x 100%, where λj is the jth eigenvalue and Σλk is the sum of all the eigenvalues.


*Ex. 5.4 Apply the factor analysis model separately to the life expectancies of men and women and compare the results.*


First create the data set that appears in the chapter. 

```{r}
"life" <- structure(.Data = list(c(63., 34., 38., 59., 56., 62., 50., 65., 56., 69., 65., 64., 56., 60., 61., 49., 59., 63., 59., 65., 65., 64.,
64., 67., 61., 68., 67., 65., 59., 58., 57.)
, c(51., 29., 30., 42., 38., 44., 39., 44., 46., 47., 48., 50., 44., 44., 45., 40., 42., 44., 44., 48., 48., 63., 43., 45., 40., 46., 45., 46., 43., 44., 46.)
, c(30., 13., 17., 20., 18., 24., 20., 22., 24., 24., 26., 28., 25., 22., 22., 22., 22., 23., 24., 28., 26., 21.,21., 23., 21., 23., 23., 24., 23., 24., 28.)
, c(13., 5., 7., 6., 7., 7., 7., 7., 11., 8., 9., 11., 10., 6., 8., 9., 6., 8., 8., 14., 9., 7., 6., 8., 10., 8., 8., 9., 10., 9., 9.) , c(67., 38., 38., 64., 62., 69., 55., 72., 63., 75., 68., 66., 61., 65., 65., 51., 61., 67., 63., 68., 67., 68., 68., 74., 67., 75., 74., 71., 66., 62., 60.), c(54., 32., 34., 46., 46., 50., 43., 50., 54., 53., 50., 51., 48., 45., 49., 41., 43., 48., 46., 51., 49., 47., 47., 51., 46., 52., 51., 51., 49., 47., 49.) , c(34., 17., 20., 25., 25., 28., 23., 27., 33., 29., 27., 29., 27., 25., 27., 23., 22., 26., 25., 29., 27., 25., 24., 28., 25., 29., 28., 28., 27., 25., 28.) , c(15., 6., 7., 8., 10., 14., 8., 9., 19., 10., 10., 11., 12., 9., 10., 8., 7., 9., 8., 13., 10., 9., 8., 10., 11., 10., 10., 10., 12., 10., 11.)), class = "data.frame", names = c("m0", "m25", "m50", "m75", "w0", "w25", "w50", "w75"), row.names = c("Algeria", "Cameroon", "Madagascar", "Mauritius", "Reunion", "Seychelles", "South Africa (C)", "South Africa (W)", "Tunisia", "Canada", "Costa Rica", "Dominican Rep.", "El Salvador", "Greenland", "Grenada", "Guatemala","Honduras", "Jamaica", "Mexico", "Nicaragua", "Panama", "Trinidad (62)", "Trinidad (67)","United States (66)", "United States (NW66)", "United States (W66)", "United States (67)", "Argentina", "Chile", "Colombia", "Ecuador"))

# inspect data set
head(life) 

# store male and female subsets 
m_life <- life[, 1:4]
f_life <- life[, 5:8]
```


To apply the EFA model on the male data set, I fit a model with k = 1 as specifying any larger values of k led to the following error ("Error in factanal(m_life, factors = 2) :
2 factors are too many for 4 variable")


```{r}
factanal(m_life, factors = 1)
```

Next, I do the same on the female data set. 

```{r}
factanal(f_life, factors = 1) 
```

Results show that a single latent factor accounted for more of the overall variance in the female data set than a single latent factor did in the male data set. For both outputs, we see that all four variables load strongly onto the latent factor. 




*Ex. 5.5 The correlation matrix given below arises from the scores of 220 boys in six school subjects: (1) French, (2) English, (3) History, (4) Arithmetic, (5) Algebra, and (6) Geometry. Find the two-factor solution from a maximum likelihood factor analysis. By plotting the derived loadings, find an orthogonal rotation that allows easier interpretation of the results.*

First I manually create the correlation matrix in order to load it into R. 

```{r}
french <- c(1.00, .44, .41, .29, .33, .25)
english <- c(0.44, 1.00, .35, .35, .32, .33)
history <- c(.41, .35, 1.00, .16, .19, .18)
arithmetic <- c(.29, .35, .16, 1.00, .59, .47)
algebra <- c(.33, .32, .19, .59, 1.00, .46)
geometry <- c(.25, .33, .18, .47, .46, 1.00)

cor_mat <- rbind(french, english, history, arithmetic, 
                 algebra, geometry)

colnames(cor_mat) <- c("french", "english", "history", 
                       "arithmetic", "algebra", "geometry")

cor_mat

```




Next, I create a two-factor model with maximum likelihood and orthogonal rotation .


```{r}
# fit the 2 factor EFA model
fa_subjects <- factanal(covmat = cor_mat, factors = 2, method = "mle")
fa_subjects 

```


Plot the factor loadings 

```{r, eval = F}
loadings <- fa_subjects$loadings
loadings[, 1]

plot(fa_subjects$loadings[,1], fa_subjects$loadings[,2], xlab = "Factor 1", ylab = "Factor 2")
text(fa_subjects$loadings[,1], fa_subjects$loadings[,2], abbreviate(rownames(cor_mat), 5), cex = cex)
```


Now I will re-run the EFA model but instead of the varimax rotation I use the promax method for an oblique rotatation. Note, while this question asks for an orthogonal rotation, I think this is another typo by the authors for two reasons. First, by default, R's `factanal()` function uses varimax rotation for an orthogonal solution. Therefore, it is misleading that the book asks us to first fit an EFA and later specify an orthogonal rotation. R will already have fit an orthogonal solution for the first model. Second, I think this is a typo by the authors because, as evidenced by the output below, an oblique rotation is a better solution for the current data. To demonstrate this point, below, I have specified 'promax' rotation for the EFA. 

```{r}
factanal(covmat = cor_mat, factors = 2, rotation = "promax", method = "mle")
```


The results indicate that, with promax rotation, the individual subjects load more cleanly onto the two latent factors. Specifically, the math subjects dominate the first factor and the humanities subjects dominate the second factor. These factors loadings are far more parsimonious than the previous EFA model where many of the items cross-loaded onto both factors (e.g. a secondary loading ~ .20+). This makes it harder to determine what constructs the latent factors refer to. Moreover, with the promax olibque rotation, the history negatively loaded onto the first factor indicating that it is negatively correlated with this factors and, instead, are more related to the second factor. 

For these reasons (and given the frequency in which we have encountered typos in this textbook), I have decided to risk the point on this question in order to present what I believe is the superior factor solution; an oblique rotation, not the orthogonal solution, which the authors asked for.


E*x. 5.6 The matrix below shows the correlations between ratings on nine statements about pain made by 123 people suffering from extreme pain. Each statement was scored on a scale from 1 to 6, ranging from agreement to disagreement.* 


*(a) Perform a principal components analysis on these data, and examine the associated scree plot to decide on the appropriate number of components.*

First, I build the correlation matrix manually given the data in the book chapter.

```{r}
item1 <- c(1.00, -.04, .61, .45, .03, -.29, -.30, .45, .30)
item2 <- c(-.04, 1.00, -.07, -.12, .49, .43, .30, -.31, -.17)
item3 <- c(.61, -.07, 1.00, .59, .03, -.13, -.24, .59, .32)
item4 <- c(.45, -.12, .59, 1.00, -.08, -.21, -.19, .63, .37)
item5 <- c(.03, .49, .03, -.08, 1.00, .47, .41, -.14, -.24)
item6 <- c(-.29, .43, -.13, -.21, .47, 1.00, .63, -.13, -.15)
item7 <- c(-.30, .30, -.24, -.19, .41, .63, 1.00, -.26, -.29)
item8 <- c(.45, -.31, .59, .63, -.14, -.13, -.26, 1.00, .40)
item9 <- c(.30, -.17, .32, .37, -.24, -.15, -.29, .40, 1.00)

# put together in matrix 
item_cor <- rbind(item1, item2, item3, item4, item5, item6, item7,
      item8, item9)
colnames(item_cor) <- c("item1", "item2", "item3", "item4", "item5", 
                        "item6", "item7", "item8", "item9")
item_cor
```


Next, I apply principal components analysis to the correlation matrix. 


```{r}
pca_1 <- princomp(item_cor, cor = T)
summary(pca_1) 
```


Plot the scree plot

```{r}
plot(pca_1, type = "l", main = "PCA Scree Plot")
```

The plot suggests that two components sufficiently represent the pattern of variance in the original data. 


*(b) Apply maximum likelihood factor analysis, and use the test described in the chapter to select the necessary number of common factors.*

The chapter demonstrates the maximum likelihood approach to determining the number of factors. 

```{r}

sapply(1:5, function(nf)
  factanal(covmat = item_cor, factors = nf, method = "mle", n.obs = 123)$PVAL)

```

The results of the maximum likelihood test indicate that the p-values for three factors is not significant and thus offers an adequate solution. 

Here is the output for the 3-factor solution 

```{r}
factanal(covmat = item_cor, factors = 2, method = "mle") 
```



*c) Rotate the factor solution selected using both an orthogonal and an oblique procedure, and interpret the results.*

First, we will fit the 3-factor model with an orthogonal rotation (same as above), which is the default for the `factanal()` function. 

```{r}
factanal(covmat = item_cor, factors = 3, rotation = "varimax", 
         method = "mle")
```




Next, I fit the same model but with an oblique rotation: 
```{r}
factanal(covmat = item_cor, factors = 3, rotation = "promax", 
         method = "mle")
```

Comparing the two solutions for each rotation strategy, we see that the orthogonal solution captures slightly greater cumulative proportion of variance than the olibque rotation. Both solutions grouped similar items. For example, items 6 and 7 loaded onto factor two in both models and items 2 and 5 loaded onto factor 3. Similarly, items 1, 4 and 8 loaded onto the first latent factor in both models. For these reasons, given the similarities between both models, the researcher is free to choose the rotation that provides the most accurate representation of their theory. In this case, since all of the items pertain to an individual's feeling of pain, I would assume that the latent factors should each be related to one another, perhaps even underlying a global pain factor. Thus, I would choose the oblique rotation. 



