---
title: "midterm_study_code"
author: "Gian Zlupko"
date: "2023-03-07"
output: html_document
---



#### Pearson Correlation and Covariance

Note: use = complete.obs argument will discard the entire row if an NA is present.

```{r}

# correlation matrix, rounded to 2 decimals 
data_cor <- round(cor(mtcars, use = "complete"), 2)
data_cor
```


```{r}
# cov matrix rounded to 2 decimals
data_cov <- round(cov(mtcars, use = "complete"), 2) 

```



Convert a covariance matrix into a correlation matrix 


```{r}
mat_one <- matrix(c(3.8778, 2.8110, 3.1480, 3.5062,
                     2.8110, 2.1210, 2.2669, 2.5690,
                     3.1480, 2.2669, 2.6550, 2.8341,
                     3.5062, 2.5690, 2.8341, 3.2352),4,4, byrow=T)


# convert the matrix, 'mat_one', into a correlation matrix 
# use round function
round(cov2cor(mat_one), 2)

```



Creating symmetric matrix 

use `forceSymmetric()` function from Matrix library if you need to convert a lower triangular matrix into a symmetric one. 

```{r}
library(Matrix)

corr_lower <- matrix(c(1, 0, 0, 0, 0, 0, 0,
                       0.402, 1, 0,0,0,0,0,
                       0.396, 0.618, 1,0,0,0,0,
                       0.301, 0.150, 0.321, 1,0,0,0,
                       0.305, 0.135, 0.289, 0.846, 1,0,0,
                       0.339, 0.206, 0.363, 0.759, 0.797, 1,0,
                       0.340, 0.183, 0.345, 0.661, 0.800, 0.736, 1),7,7, byrow = T)

# use forceSymmetric() function from Matrix library
forceSymmetric(corr_lower, uplo = "L")  
```







#### for loop 

Simple for loop function in R. Below, the loop writes over the values in the first three columns with the respective column mean. 

```{r}


for (cols in c(1,2,3)) { 
  
  mtcars[, cols] <- mean(mtcars[, cols])
  
}

# inspect the first three columns where the values were overwritten 
head(mtcars) 
```



#### Normal Probability Plots 


```{r}
library(HSAUR2) 

# create single normal probability plot 
qqnorm(pottery[, 1], main = "AL203") 

```


Create a grid of normal probability plots in data set 
```{r}

# create normal probability plots for each variable 

sapply(colnames(pottery)[1:9], function(x) { 
  
  qqnorm(pottery[[x]], main = x)
  qqnorm(pottery[[x]])
  
  })
```



#### Create a distance matrix

Euclidean
```{r}
mat_one

# use dist() function
dist(mat_one, method = "euclidean") 
```


Manhattan

```{r}
dist(mat_one, method = "manhattan")
```




#### Principal Components Analysis (PCA)

Method 1: Applied to cov or cor matrix 

In Everitt & Hothon (2011), the authors recommend that the use of a covariance matrix for PCA should only be used when the data are measured on roughly the same scale. This is not common in practice and so a correlation matrix is a good approach. 

The `princomp()` function performs PCA from R stats. You can also use `prcomp` but this function does not easily provide loadings as is shown below using the summary on the PCA model object. 

```{r}
# create data subset
mtcars
mt_cor <- cor(mtcars)

# run PCA: store as a PCA model object
# note: specify covmat argument when running on a cov or cor mat. Use covmat for both. 
pca_1 <- princomp(covmat = mt_cor) 

# view PCA output 
summary(pca_1, loadings = TRUE) 

```



Scree Plot 

Use the `type = "l"` argument in the `plot()` function to specify a line plot. 
```{r}

plot(pca_1, type = "l",
     main = "Scree Plot")

```



Method 2: applied directly to data

```{r}
head_dat <- headsize[, c("l1", "l2")]
# cor matrix 
head_cor <- cor(headsize)
head_cor

# PCA
head_pca <- princomp(head_dat)

# PCA output
summary(head_pca, loadings = TRUE)
```

```{r}
library(factoextra)

# graph biplot 
fviz_pca_var(head_pca,
             col.var = "contrib", # Color by contributions to the PC
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE     # Avoid text overlapping
             )

```



factoexra library for enhanced PCA viz 

Use mtcars data set 

```{r}

mt_cor <- cor(mtcars) 

mt_pca <- princomp(mt_cor, cor = T)
summary(mt_pca)

# enhanced scree plot
fviz_eig(mt_pca)

# Graph of car features. Features with a similar profile are grouped together.

fviz_pca_ind(mt_pca,
             col.ind = "cos2", # Color by the quality of representation
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE     # Avoid text overlapping
             )

```




```{r}
library(HSAUR2) 
library(tidyverse) 
# reversing the values 
heptathlon$hurdles <- with(heptathlon, max(hurdles) - hurdles)
heptathlon$run200m <- with(heptathlon, max(run200m) - run200m)
heptathlon$run800m <- with(heptathlon, max(run800m) - run800m)
heptathlon <- heptathlon %>% select(-score) # remove score
# build scatterplot matrix 
plot(heptathlon, pch = ".", cex = 1.5)

```



```{r}
hep_cor <- round(cor(heptathlon), 2)
```


```{r}
pca_hep <- prcomp(heptathlon, scale = T)
pca_hep
summary(pca_hep, loadings = TRUE)
```

```{r}
plot(pca_hep) 
plot(pca_hep, type = "l")
```




```{r}
biplot(pca_hep, col = c("gray", "black"))
```







#### Multidimensional Scaling 

Garden flower example
```{r}

library("MVA")
data(gardenflowers)

# MDS 
d_mds <- cmdscale(gardenflowers, k = 17, eig = T)

# get eigenvalues
eigen <- d_mds$eig
eigen
```

Note: some of the eigenvalues are negative which means the distance is not Euclidean. 
```{r}
# cumulative proportion of variance

cumsum(abs(eigen)) / sum(abs(eigen)) # method 1 

cumsum(abs(eigen)^2) / sum(abs(eigen)^2) # method 2 
```



QQNorm 

```{r}
pottery 

qqnorm(pottery$Al2O3) 

# to apply qqnorm to all the columns 
#sapply(pottery, qqnorm)
```



Create a matrix 
```{r}
mat_a <- matrix(c(1,2,2,3,4,5,6,7,8,9,1,2,3,4,5,6,7,8,9,10), 5,2, byrow = T)


dist_matA <- dist(mat_a) 

mds1 <- cmdscale(dist_matA, eig = T) 

mds1$eig

# cum sum 
cumsum(abs(mds1$eig)^2) / sum(abs(mds1$eig)^2)

```




```{r}
pollution <- USairpollution
pollution


```

